{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLVC 2017\n",
    "# Tutorial 11: CIFAR-10 Classification (AlexNet)\n",
    "\n",
    "### Cifar-10 dataset (https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import struct\n",
    "import torch\n",
    "from PIL import Image\n",
    "#import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from torchvision import models,datasets,transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    pinMem = True # Flag for pinning GPU memory\n",
    "    print('GPU is available!')\n",
    "else:\n",
    "    pinMem = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/iteradmin/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/home/iteradmin/anaconda2/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/home/iteradmin/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/home/iteradmin/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/iteradmin/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/iteradmin/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/home/iteradmin/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "  File \"/home/iteradmin/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    racquire()\n",
      "    return recv()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/iteradmin/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "[ transforms.Resize(size=(224,224)),\n",
    " transforms.ToTensor()])\n",
    " #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.ImageFolder(root=\"train\",transform=transform)\n",
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size=1,shuffle=True,         num_workers=2)\n",
    "\n",
    "testset = datasets.ImageFolder(root='tests',transform=transform)\n",
    "testLoader = torch.utils.data.DataLoader(testset, batch_size=1,shuffle=True,     num_workers=2)\n",
    "\n",
    "classes=('1','0')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainLoader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of samples in train set: 212\n",
      "No. of samples in test set: 48\n"
     ]
    }
   ],
   "source": [
    "# Size of train and test datasets\n",
    "print('No. of samples in train set: '+str(len(trainLoader.dataset)))\n",
    "print('No. of samples in test set: '+str(len(testLoader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d (3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "    (3): Conv2d (64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "    (6): Conv2d (192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d (384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096)\n",
      "    (fc): Linear(in_features=4096, out_features=2)\n",
      "    (softmax): LogSoftmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# AlexNet\n",
    "net = models.alexnet()\n",
    "new_classifier = nn.Sequential(*list(net.classifier.children())[:-5])\n",
    "new_classifier.add_module('fc',nn.Linear(4096,2))\n",
    "new_classifier.add_module('softmax',nn.LogSoftmax())\n",
    "net.classifier = new_classifier\n",
    "print(net)\n",
    "if use_gpu:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # Negative Log-likelihood\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4) # Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "trainLoss = []\n",
    "testAcc = []\n",
    "start = time.time()\n",
    "for epoch in range(iterations):\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0    \n",
    "    batchNum = 0\n",
    "#     for data in trainLoader:\n",
    "    for i, data in enumerate(trainLoader, 0):\n",
    "       \n",
    "        inputs,labels = data\n",
    "        # Wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.float().cuda()), \\\n",
    "                Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs.float()), Variable(labels)         \n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Feed-forward input data through the network        \n",
    "        outputs = net(inputs)\n",
    "        # Compute loss/error\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        optimizer.step()\n",
    "        # Accumulate loss per batch\n",
    "        runningLoss += loss.data[0] \n",
    "        batchNum += 1\n",
    "        \n",
    "    print \"training done\"\n",
    "    avgTrainLoss = runningLoss/212\n",
    "    trainLoss.append(avgTrainLoss)\n",
    "    \n",
    "    # Evaluating performance on test set for each epoch\n",
    "    running_correct = 0\n",
    "    for i, data in enumerate(testLoader, 0):\n",
    "        \n",
    "        inputs,labels = data\n",
    "        # Wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs.cuda())\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = predicted.cpu()\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "        running_correct += (predicted == labels).sum()\n",
    "        print(running_correct)\n",
    "        \n",
    "    print \"training done\"\n",
    "\n",
    "    avgTestAcc = running_correct/48.0\n",
    "    \n",
    "    testAcc.append(avgTestAcc)\n",
    "        \n",
    "    # Plotting training loss vs Epochs\n",
    "    fig1 = plt.figure(1)        \n",
    "    plt.plot(range(epoch+1),trainLoss,'r-',label='train')        \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Training loss')   \n",
    "    # Plotting testing accuracy vs Epochs\n",
    "    fig2 = plt.figure(2)        \n",
    "    plt.plot(range(epoch+1),testAcc,'g-',label='test')        \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Testing accuracy')    \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('At Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f} ; Testing Acc: {:.3f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,avgTrainLoss,avgTestAcc*100,epochEnd//60,epochEnd%60))\n",
    "end = time.time()-start \n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(end//60,end%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
